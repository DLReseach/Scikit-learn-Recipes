{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import pandas as pd  \n",
    "from sklearn.preprocessing import Binarizer, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.cluster import KMeans  \n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Wine2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale the data\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "data.loc[:, data.columns != 'class'] = mms.fit_transform(data.loc[:, data.columns != 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters= 3)\n",
    "kmeans.fit(data.drop('class',axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans = kmeans.predict(data.drop('class',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cluster centers and samples \n",
    "sns.scatterplot(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], \n",
    "                marker='+', \n",
    "                color='black', \n",
    "                s=200);\n",
    "sns.scatterplot(data['Alcohol'], data['Malic_acid'], hue=y_kmeans, \n",
    "                palette=sns.color_palette(\"Set1\", n_colors=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the distance from the center in order to find outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squared distance to cluster center\n",
    "X_dist = kmeans.transform(data.drop('class',axis=1))**2\n",
    "\n",
    "df = pd.DataFrame(X_dist.sum(axis=1).round(2), columns=['sqdist'])\n",
    "df['label'] = y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[max_indices, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[max_indices, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each cluster, find the furthest point\n",
    "max_indices = []\n",
    "for label in np.unique(kmeans.labels_):\n",
    "    X_label_indices = np.where(y_kmeans==label)[0]\n",
    "    max_label_idx = X_label_indices[np.argmax(X_dist[y_kmeans==label].sum(axis=1))]\n",
    "    max_indices.append(max_label_idx)\n",
    "\n",
    "# replot, but highlight the furthest point\n",
    "sns.scatterplot(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], \n",
    "                marker='+', \n",
    "                color='black', \n",
    "                s=200)\n",
    "\n",
    "sns.scatterplot(data.iloc[:, 2], data.iloc[:, 3], hue=y_kmeans, \n",
    "                palette=sns.color_palette(\"Set1\", n_colors=3))\n",
    "# highlight the furthest point in black\n",
    "sns.scatterplot(data.iloc[max_indices, 2], data.iloc[max_indices, 3], color='black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawbacks of k-means clustering\n",
    "* Difficult to predict number of clusters \n",
    "* It doesn't work well when there is a global cluster like in our dataset\n",
    "* Different initial partitions can result in different final clusters\n",
    "* It does not work well with clusters (in the original data) of different sizes and densities - it assumes that all clusters have same variance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
